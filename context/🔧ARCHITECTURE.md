# 1. Architecture Overview

Status: alinhado com a Arquitetura Consolidada V4 (RAG + Supabase + Caddy) e gestÃ£o via Portainer.

Componentes e conexÃµes:
- Supabase (db) inicializado primeiro por `start_services.py` com schema RAG
- RAG API exposto via Caddy em `RAG_HOSTNAME` (padrÃ£o `:8009`)
- IngestÃ£o isolada por perfil `ingestion`
- Langfuse (observabilidade completa) e Redis/Valkey
- Portainer para gestÃ£o visual
- LiteLLM externo no host; serviÃ§os consulentes usam `LLM_BASE_URL`


> **ğŸ“š DocumentaÃ§Ã£o de ReferÃªncia:**
> - [CLAUDE.md](../CLAUDE.md) - Guia completo de comandos e arquitetura
> - [ğŸ“„CONTEXT.md](ğŸ“„CONTEXT.md) - VisÃ£o geral do fluxo de dados e camadas
> - [ğŸ—„ï¸DATABASE_SETUP.md](ğŸ—„ï¸DATABASE_SETUP.md) - EstratÃ©gia dual-database detalhada

This guide details the construction of a production-grade, graph-enhanced RAG (Retrieval-Augmented Generation) system combining the efficiency of LightRAG with a **dual-database backend**: PostgreSQL for vector storage and Neo4j for graph operations.

## 1.0 Dual-Database Architecture (Critical Design Decision)

O ai-stack implementa uma **arquitetura dual-database** para separaÃ§Ã£o de responsabilidades:

| Database | Porta | Superuser | Responsabilidade | Acesso |
| :--- | :---: | :--- | :--- | :--- |
| **supabase-db** | 5432 | supabase_admin | Core ai-stack (RAG, n8n, Supabase services) | `docker exec -it supabase-db psql -U supabase_admin -d postgres` |
| **postgres-plane** | 5433 | postgres | Plane project management (isolado) | `docker exec -it postgres-plane psql -U postgres -d plane_db` |

**MotivaÃ§Ã£o da Arquitetura:**
- âœ… **Isolamento Total**: Plane requer configuraÃ§Ãµes especÃ­ficas que conflitam com Supabase
- âœ… **Zero Conflitos**: UsuÃ¡rios, roles e schemas completamente separados
- âœ… **Escalabilidade Independente**: Recursos dedicados por serviÃ§o
- âœ… **Upgrades Seguros**: Atualizar um banco sem afetar o outro
- âœ… **Backups Isolados**: EstratÃ©gias de recovery independentes

### 1.0.1 Componentes da Stack

| Component | Responsibility | Technology Stack |
| :--- | :--- | :--- |
| **Data Layer** | Stores vectors and manages relationships. | PostgreSQL (pgvector) + Neo4j |
| **RAG Engine** | Executes dual-level retrieval and ingestion. | LightRAG |
| **LLM Gateway** | Provides unified, centralized access to LLMs. | LiteLLM Proxy (Host:4000) |
| **Agent Interface** | Translates REST API calls into AI agent tools. | FastMCP Server (Model Context Protocol - MCP) |
| **User Interface** | Facilitates agentic interaction. | Claude Code CLI |
| **Project Management** | Optional AI-powered project orchestration | Archon (independent stack) |


## Key Components

- **Data Layer**: PostgreSQL (pgvector) + Neo4j (graph database)
- **RAG Engine**: LightRAG with dual-level retrieval (vector + graph)
- **Multimodal Processing**: RAG-Anything integration
- **LLM Gateway**: LiteLLM proxy for unified model access
- **Agent Interface**: MCP servers for AI tool integration
- **Development Framework**: BMAD methodology with Claude Code

**Critical Design Decision:** The graph database implementation targets **Neo4j** for production deployment.

The system flow involves the **Claude Code CLI** interacting via MCP with the **FastMCP Server**, which serves as an agentic bridge and handles memory augmentation. This server calls the **LightRAG Server** (the RAG orchestration layer), which uses the **LiteLLM Proxy** (LLM abstraction layer) to communicate with external LLMs, and ultimately retrieves data from the **PostgreSQL + Neo4j** Data Persistence Layer.


# 1. Arquitetura Expandida: Sistema RAG Multimodal com Grafos para ProduÃ§Ã£o

## 1.1 Fundamentos Arquiteturais Unificados

### EstratÃ©gia de Framework Unificado
O sistema adota o LightRAG como framework central para recuperaÃ§Ã£o hÃ­brida (vetorial + grafos), complementado pelo RAG-Anything para processamento multimodal unificado. Esta abordagem elimina a complexidade de integrar mÃºltiplas bibliotecas especializadas, proporcionando uma interface coesa para consulta de documentos com conteÃºdo multimodal intercalado.

### Backend Unificado PostgreSQL
PostgreSQL com extensÃµes pgvector e Neo4j substitui uma stack distribuÃ­da de bancos especializados, reduzindo significativamente a complexidade operacional enquanto mantÃ©m consistÃªncia transacional ACID entre modelos de dados.

**ExtensÃµes CrÃ­ticas:**
- **pgvector**: Busca de similaridade vetorial com algoritmos HNSW e IVFFlat
- **NEO4J**: Funcionalidade de banco de grafos.
- **Compatibilidade**: PostgreSQL 15-16 para suporte completo Ã s extensÃµes

### Gateway de Modelos Unificado
LiteLLM fornece abstraÃ§Ã£o unificada para 100+ APIs de LLM, padronizando para formato OpenAI e permitindo troca de provedores via configuraÃ§Ã£o.

## 1.2 Componentes e Fluxos de Dados Expandidos

### Pipeline de IngestÃ£o Multimodal
```
Ingest â†’ Parse â†’ Chunk â†’ Enrich â†’ Index
```

**EstÃ¡gio 1: IngestÃ£o & AnÃ¡lise**
- **Parser de Alta Fidelidade**: MinerU/Docling para decomposiÃ§Ã£o estrutural de PDF, DOCX, PPTX
- **PrÃ©-processamento Padronizado**: ConversÃ£o de formatos simples (.txt, .md) para PDF temporÃ¡rio
- **PreservaÃ§Ã£o de Hierarquia**: ManutenÃ§Ã£o da estrutura semÃ¢ntica original (parÃ¡grafos, seÃ§Ãµes, tabelas, imagens)

**EstÃ¡gio 2: FragmentaÃ§Ã£o (Chunking)**
- **Texto**: EstratÃ©gias configurÃ¡veis (fixa, semÃ¢ntica LLM, recursiva hierÃ¡rquica)
- **Tabelas**: RepresentaÃ§Ã£o estruturada (Markdown/JSON) + resumo em linguagem natural
- **Imagens**: Metadados ricos via VLM (legenda, OCR, objetos, relaÃ§Ãµes espaciais)

**EstÃ¡gio 3: Enriquecimento & ExtraÃ§Ã£o de Conhecimento**
- **LLM Poderoso**: Modelos 32B+ parÃ¢metros, contexto 64K tokens (Claude 3 Opus, Gemini 1.5 Pro)
- **ExtraÃ§Ã£o Estruturada**: Entidades e relacionamentos em schema JSON padronizado
- **DeduplicaÃ§Ã£o**: FusÃ£o de entidades/relacionamentos idÃªnticos para otimizaÃ§Ã£o do grafo

**EstÃ¡gio 4: IndexaÃ§Ã£o**
- **PersistÃªncia HÃ­brida**: PostgreSQL (chunks vetoriais) + Neo4j (grafos de conhecimento)
- **Metadados Ricos**: SumÃ¡rios, keywords, estratÃ©gia de chunking em JSONB

### Pipeline de InferÃªncia HÃ­brida
```
Consulta â†’ PrÃ©-processamento â†’ RecuperaÃ§Ã£o HÃ­brida â†’ Reranking â†’ SÃ­ntese â†’ Resposta
```

**RecuperaÃ§Ã£o Dual-Level:**
- **NÃ­vel Local (Vetorial)**: Similaridade semÃ¢ntica em chunks especÃ­ficos
- **NÃ­vel Global (Grafo)**: Travessia de relacionamentos para contextos amplos
- **CombinaÃ§Ã£o HÃ­brida**: Resultados abrangentes com mÃ¡ximo contexto

## 1.3 Arquitetura de Plugin para Modalidades

### Interface BaseModalityHandler
```python
class BaseModalityHandler(ABC):
    @abstractmethod
    def can_handle(self, mimetype: str) -> bool:
        """Verifica suporte para tipo MIME"""
        pass
    
    @abstractmethod 
    def process(self, data: Any, metadata: Dict) -> List:
        """Processa dados da modalidade em chunks estruturados"""
        pass
```

**Handlers Especializados:**
- **TextHandler**: Texto plano e Markdown com estratÃ©gias de chunking
- **TableHandler**: Dados tabulares com representaÃ§Ã£o estruturada + resumo
- **ImageHandler**: Processamento visual via VLM (legenda, OCR, detecÃ§Ã£o de objetos)
- **EquationHandler**: EquaÃ§Ãµes LaTeX com validaÃ§Ã£o e explicaÃ§Ã£o

### Descoberta DinÃ¢mica de Plugins
- Registro automÃ¡tico de handlers via scanning de diretÃ³rio
- Roteamento inteligente baseado em tipo MIME
- Extensibilidade sem modificaÃ§Ã£o do core do pipeline

## 1.4 EstratÃ©gia de Dados e Esquema Unificado

### PrincÃ­pios de Design do Esquema
- **Granularidade**: Documentos, chunks e elementos de grafo como entidades interconectadas
- **Metadados Ricos**: JSONB para contexto, rastreabilidade e filtragem
- **SeparaÃ§Ã£o LÃ³gica**: Tabelas dedicadas para KV, Vector, Graph, Status

### Esquema PostgreSQL Otimizado
```sql
-- ExtensÃµes essenciais
CREATE EXTENSION IF NOT EXISTS vector;
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

-- Tabela de documentos fonte
CREATE TABLE documents (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    doc_hash VARCHAR(64) UNIQUE NOT NULL, -- SHA-256 para idempotÃªncia
    source_uri TEXT NOT NULL,
    file_name TEXT,
    file_type VARCHAR(50),
    metadata JSONB,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Tabela de status de processamento  
CREATE TABLE doc_status (
    document_id UUID PRIMARY KEY REFERENCES documents(id),
    status doc_processing_status DEFAULT 'PENDING',
    last_error TEXT,
    updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- Tabela de chunks (KV + Vector)
CREATE TABLE chunks (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    chunk_hash VARCHAR(64) UNIQUE NOT NULL,
    document_id UUID REFERENCES documents(id),
    chunk_order_index INT NOT NULL,
    content TEXT NOT NULL, -- Texto original para contexto LLM
    cleaned_content TEXT, -- Texto normalizado para embeddings
    embedding VECTOR(1536) NOT NULL, -- DimensÃ£o fixa do modelo
    metadata JSONB,
    created_at TIMESTAMPTZ DEFAULT NOW()
);
```

## 1.5 OrquestraÃ§Ã£o de Modelos e ConfiguraÃ§Ã£o

### AbstraÃ§Ã£o LiteLLM
```yaml
# config.yaml - ConfiguraÃ§Ã£o como cÃ³digo
model_list:
  - model_name: "generation-model-default"
    litellm_params:
      model: "azure/gpt-4o-prod-deployment"
      api_key: "os.environ/AZURE_PROD_API_KEY"

  - model_name: "embedding-model-default"  
    litellm_params:
      model: "openai/text-embedding-3-large"
      api_key: "os.environ/OPENAI_API_KEY"
```

### SeleÃ§Ã£o EstratÃ©gica de Modelos
- **IndexaÃ§Ã£o (ExtraÃ§Ã£o)**: LLMs poderosos (32B+, contexto 64K) para precisÃ£o
- **Consulta (GeraÃ§Ã£o)**: Modelos com forte raciocÃ­nio e seguimento de instruÃ§Ãµes
- **Embeddings**: Modelos multilÃ­ngues de alta performance (BAAI bge-m3, OpenAI text-embedding-3-large)
- **Rerankers**: Modelos especializados (BAAI bge-reranker-v2-m3, Cohere) para precisÃ£o

### Gerenciamento de Contexto de API
```python
class RequestContextManager:
    def build_prompt(self, user_query: str, conversation_history: list, local_context: dict) -> list:
        """ConstrÃ³i mensagens finais para API LLM com contexto recuperado"""
        retrieved_docs, retrieved_graph_data = self.db_retriever.hybrid_retrieve(user_query)
        formatted_context = self._format_retrieved_context(retrieved_docs, retrieved_graph_data)
        # ... construÃ§Ã£o do prompt aumentado
```

## 1.6 ImplantaÃ§Ã£o e OperaÃ§Ãµes em ProduÃ§Ã£o

### ContainerizaÃ§Ã£o Otimizada
```dockerfile
# Build multi-estÃ¡gio para imagens seguras e enxutas
FROM python:3.11-slim-bookworm AS builder
# ... instalaÃ§Ã£o de dependÃªncias
FROM python:3.11-slim-bookworm
USER appuser  # UsuÃ¡rio nÃ£o-root para seguranÃ§a
COPY --from=builder /usr/local/lib/python3.11/site-packages /usr/local/lib/python3.11/site-packages
```

### OrquestraÃ§Ã£o com Docker Compose
```yaml
services:
  database:
    image: postgres:16
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
  
  api:
    build: .
    depends_on:
      database:
        condition: service_healthy  # Espera saÃºde do banco
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
```

### SeguranÃ§a com Docker Secrets
- Credenciais via arquivos montados em `/run/secrets/`
- VariÃ¡veis `_FILE` para leitura segura (ex: `POSTGRES_PASSWORD_FILE`)
- Isolamento em filesystem in-memory (tmpfs)

## 1.7 AvaliaÃ§Ã£o de Desempenho e OtimizaÃ§Ã£o

### Framework de AvaliaÃ§Ã£o Data-Driven
**Dataset "Golden" Iterativo:**
- InÃ­cio com 10-20 exemplos curados manualmente
- GeraÃ§Ã£o semi-automÃ¡tica de tripletas (pergunta-resposta-contexto) via LLM
- RevisÃ£o humana-in-the-loop para qualidade
- EvoluÃ§Ã£o contÃ­nua com casos de falha reais

### MÃ©tricas de AvaliaÃ§Ã£o Abrangentes
| Categoria | MÃ©trica | MÃ©todo | PropÃ³sito |
|-----------|---------|--------|-----------|
| RecuperaÃ§Ã£o | Context Precision@K | ProporÃ§Ã£o de documentos recuperados relevantes | PrecisÃ£o do retriever |
| RecuperaÃ§Ã£o | Context Recall@K | ProporÃ§Ã£o de documentos relevantes recuperados | Recall do retriever |
| GeraÃ§Ã£o | Faithfulness | LLM-as-judge: suporte ao contexto | PrevenÃ§Ã£o de alucinaÃ§Ãµes |
| GeraÃ§Ã£o | Answer Relevance | LLM-as-judge: pertinÃªncia Ã  pergunta | Qualidade da resposta |
| GeraÃ§Ã£o | Answer Correctness | LLM-as-judge: comparaÃ§Ã£o com ground truth | PrecisÃ£o factual |

### Metodologia de Tuning SistemÃ¡tico
**HiperparÃ¢metros CrÃ­ticos:**
- EstratÃ©gia de chunking: `chunk_size`, `chunk_overlap`, mÃ©todo
- Modelo de embeddings: comparaÃ§Ã£o de performance
- ParÃ¢metros de recuperaÃ§Ã£o: `top_k`, reranking
- Ãndices vetoriais: HNSW (`m`, `ef_construction`, `ef_search`)
- Templates de prompt: A/B testing para faithfulness

**Log Experimental Estruturado:**
| Experimento | ParÃ¢metro | Valores | MÃ©tricas | ConclusÃµes |
|-------------|-----------|---------|----------|------------|

### Dashboard de Monitoramento ContÃ­nuo
- Pipeline de avaliaÃ§Ã£o automatizada (execuÃ§Ã£o noturna)
- Plotagem temporal de mÃ©tricas-chave
- Alertas para regressÃµes de performance
- ValidaÃ§Ã£o de mudanÃ§as (cÃ³digo, modelos, dados)

---

---
## 1.4 Arquitetura Detalhada do Sistema Graph-RAG

### 1.4.1 Componentes Principais e Fluxo de Dados

```mermaid
graph TB
    subgraph "Camada de Clientes"
        A[Claude Code CLI]
        B[OpenWebUI]
        C[n8n - AutomaÃ§Ã£o]
    end
    
    subgraph "Camada de API e OrquestraÃ§Ã£o"
        D[FastMCP Server]
        E[LightRAG Server]
        F[LiteLLM Proxy]
    end
    
    subgraph "Camada de Dados"
        G[PostgreSQL + pgvector]
        H[Neo4j Graph Database]
    end
    
    A -->|MCP| D
    B -->|HTTP| E
    C -->|HTTP| E
    D -->|HTTP| E
    E -->|API Calls| F
    E -->|Vector Queries| G
    E -->|Graph Traversal| H
```

### 1.4.2 EspecificaÃ§Ãµes TÃ©cnicas dos Componentes

#### LightRAG Server (Porta 9621)
- **FunÃ§Ã£o**: OrquestraÃ§Ã£o RAG e processamento multimodal
- **RecuperaÃ§Ã£o Dual-Level**: 
  - **Low-Level**: Busca vetorial via PostgreSQL/pgvector
  - **High-Level**: Travessia de grafos via Neo4j
- **Modos de OperaÃ§Ã£o**: `naive`, `local`, `global`, `hybrid` (recomendado)

#### PostgreSQL + pgvector
- **ExtensÃµes**: pgvector, uuid-ossp, full-text search
- **Esquema Otimizado**: 
  - Tabelas: `documents`, `doc_status`, `chunks`, `code_examples`
  - Ãndices HNSW paraç›¸ä¼¼idade de cosseno
  - Hash SHA-256 para idempotÃªncia na ingestÃ£o

#### Neo4j Graph Database
- **Portas**: 7474 (Browser), 7687 (Bolt)
- **Esquema**: Entidades e relacionamentos com propriedades
- **Ãndices**: Otimizados para travessia de grafos e consultas Cypher

#### LiteLLM Proxy (Porta 4000)
- **UnificaÃ§Ã£o**: 100+ modelos LLM via interface OpenAI
- **Gerenciamento Centralizado**: Chaves de API, retries, fallbacks
- **Modelos Suportados**: Claude, GPT-4, embeddings, modelos visuais

## 1.5 Fluxos de Trabalho de Ponta a Ponta

### 1.5.1 Consulta RAG via Agente MCP

1. **Prompt do UsuÃ¡rio** â†’ Claude Code CLI
2. **Chamada MCP** â†’ `query_knowledge_base` no FastMCP Server
3. **Contexto Persistente** â†’ Leitura do Memory Bank (`project_brief.md`, `tech_stack.md`)
4. **API LightRAG** â†’ `POST /query` com consulta aumentada
5. **RecuperaÃ§Ã£o HÃ­brida**:
   - **Vetorial**: Similaridade semÃ¢ntica nos chunks do PostgreSQL
   - **Grafo**: Travessia de relacionamentos no Neo4j
6. **SÃ­ntese** â†’ LLM gera resposta com contexto combinado
7. **Resposta Final** â†’ Retorno atravÃ©s da cadeia MCP â†’ UsuÃ¡rio

### 1.5.2 IngestÃ£o de Documentos via n8n

1. **Trigger** â†’ Novo arquivo no diretÃ³rio `./memory-bank`
2. **IdempotÃªncia** â†’ CÃ¡lculo de hash SHA-256 e verificaÃ§Ã£o de duplicata
3. **API LightRAG** â†’ `POST /documents/file` para processamento
4. **Pipeline Multimodal**:
   - **AnÃ¡lise**: DecomposiÃ§Ã£o em texto, imagens, tabelas
   - **Enriquecimento**: 
     - Texto â†’ ExtraÃ§Ã£o de entidades/relacionamentos
     - Imagens â†’ DescriÃ§Ãµes via VLM (GPT-4o)
     - Tabelas â†’ Resumos em linguagem natural
5. **PersistÃªncia HÃ­brida**:
   - **PostgreSQL**: Chunks vetorizados e metadados
   - **Neo4j**: Entidades e relacionamentos extraÃ­dos
6. **AtualizaÃ§Ã£o de Status** â†’ Tabela `doc_status` marcada como `COMPLETED`

## 1.6 EstratÃ©gias de OtimizaÃ§Ã£o em ProduÃ§Ã£o

### 1.6.1 Performance e Escalabilidade

```sql
-- Ãndices PostgreSQL para performance RAG
CREATE INDEX idx_chunks_embedding_hnsw ON chunks USING hnsw (embedding vector_cosine_ops);
CREATE INDEX idx_chunks_fts ON chunks USING GIN (fts_vector);
CREATE INDEX idx_documents_hash ON documents(doc_hash);

-- ConfiguraÃ§Ãµes de performance no postgresql.conf
shared_buffers = '1GB'
work_mem = '256MB'
maintenance_work_mem = '512MB'
effective_cache_size = '4GB'
```

### 1.6.2 Monitoramento e Observabilidade

```python
# MÃ©tricas essenciais para sistema RAG em produÃ§Ã£o
rag_metrics = {
    'query_latency': 'Tempo de resposta das consultas',
    'retrieval_accuracy': 'PrecisÃ£o na recuperaÃ§Ã£o de contexto',
    'cache_hit_rate': 'Taxa de acerto do cache de embeddings',
    'token_usage': 'Uso de tokens por modelo LLM',
    'vector_similarity_threshold': 'Limiar deç›¸ä¼¼idade para resultados relevantes'
}
```

### 1.6.3 SeguranÃ§a e Boas PrÃ¡ticas

- **Varredura AutomÃ¡tica**: IntegraÃ§Ã£o Simgrip com 2.000+ regras de seguranÃ§a
- **RevisÃ£o de CÃ³digo**: ValidaÃ§Ã£o humana para cÃ³digo de infraestrutura
- **GestÃ£o de Credenciais**: CentralizaÃ§Ã£o via LiteLLM Proxy
- **ContainerizaÃ§Ã£o**: Isolamento de serviÃ§os via Docker

## 1.7 BenefÃ­cios da Arquitetura Unificada

### 1.7.1 Vantagens Operacionais
- **ReduÃ§Ã£o de Complexidade**: PostgreSQL Ãºnico vs mÃºltiplos bancos especializados
- **ConsistÃªncia Transacional**: OperaÃ§Ãµes ACID entre dados vetoriais e de grafo
- **Performance Otimizada**: Consultas hÃ­bridas sem latÃªncia de rede entre sistemas
- **ManutenÃ§Ã£o Simplificada**: Backup, recovery e monitoramento unificados

### 1.7.2 Vantagens de Desenvolvimento
- **API Coesa**: Interface Ãºnica para operaÃ§Ãµes RAG complexas
- **Desacoplamento de Componentes**: Desenvolvimento independente por camada
- **Extensibilidade**: AdiÃ§Ã£o fÃ¡cil de novos modelos e provedores via LiteLLM
- **Ecosistema Rico**: IntegraÃ§Ã£o com ferramentas MCP existentes

---
*Nota: Este conteÃºdo deve ser concatenado ao arquivo alvo identificado*
---

#### **4.1 Novo Diagrama Arquitetural: Multi-Agent Orchestration**

```mermaid
graph TB
    subgraph "Camada de Clientes & Terminais"
        A["ğŸ–¥ï¸ Claude Code<br/>(Local Dev)"]
        B["âŒ¨ï¸ GitHub Copilot CLI<br/>(Terminal Agent)"]
        C["ğŸŒ OpenWebUI<br/>(Web Interface)"]
    end
    
    subgraph "Camada de OrquestraÃ§Ã£o & AgÃªncia (NOVO)"
        D["ğŸ›ï¸ Mission Control<br/>(Agent HQ)"]
        E["ğŸ”€ Agent Router<br/>(LiteLLM Enhanced)"]
        F["ğŸ“‹ n8n Orchestrator<br/>(GitHub â†” Plane)"]
    end
    
    subgraph "Camada MCP & Ferramentas"
        G["ğŸ”— FastMCP Server"]
        H["ğŸ”— GitHub MCP Server"]
        I["ğŸ”— Plane MCP Server"]
        J["ğŸ”— Custom MCP Servers"]
    end
    
    subgraph "Camada de RecuperaÃ§Ã£o & SÃ­ntese"
        K["ğŸ§  LightRAG Server<br/>(RAG Hybrid)"]
        L["ğŸ¯ LiteLLM Proxy<br/>(Model Gateway)"]
    end
    
    subgraph "Camada de PersistÃªncia"
        M["ğŸ—„ï¸ PostgreSQL<br/>(Vectors + pgvector)"]
        N["ğŸ“Š Neo4j<br/>(Knowledge Graphs)"]
    end
    
    A -->|MCP Calls| G
    B -->|MCP Calls| H
    C -->|REST| K
    
    D -->|Route Tasks| E
    E -->|Selects Model| L
    F -->|Webhook Events| D
    
    G â†â†’ E
    H â†â†’ D
    I â†â†’ F
    J â†â†’ E
    
    K â†â†’ M
    K â†â†’ N
    L â†â†’ M
    
    style D fill:#ffeb3b,stroke:#333,stroke-width:3px,color:#000
    style B fill:#00bcd4,stroke:#333,stroke-width:3px,color:#fff
    style E fill:#ff9800,stroke:#333,stroke-width:3px,color:#fff
```

#### **4.2 GovernanÃ§a de SeguranÃ§a: Camada Agent HQ**

```yaml
# .github/agent-security-policy.yml

agent_security_framework:
  
  authentication:
    - github_app_verification: true
    - mcp_server_validation: true
    - rate_limiting: "1000 req/min per agent"
  
  authorization:
    - branch_restrictions:
        main: "only-approved-agents"
        develop: "all-agents"
        feature/*: "all-agents"
    
    - file_restrictions:
        - pattern: "src/security/**"
          allowed_agents: ["senior-developer-agent"]
          requires_approval: true
        - pattern: "config/secrets/**"
          allowed_agents: []
          requires_approval: true
    
    - action_restrictions:
        deploy:
          allowed_agents: ["deployment-agent"]
          requires_approval: true
          approval_type: "human-only"
        
        delete_database:
          allowed_agents: []
          requires_approval: true
          approval_type: "2-factor-human"

  audit_logging:
    enabled: true
    destination: "cloudwatch"
    retention: "90 days"
    events:
      - "agent_execution_start"
      - "agent_execution_end"
      - "file_modification"
      - "approval_request"
      - "security_incident"

  incident_response:
    auto_rollback: true
    rollback_window: "1 hour"
    notification_channels: ["slack", "email", "pagerduty"]
    escalation_threshold:
      failure_rate: "20%"
      error_type: "security"
```

---

## 2. IntegraÃ§Ã£o Opcional: Archon Project Management

### 2.1 Arquitetura de IntegraÃ§Ã£o Archon

O **Archon** Ã© um sistema modular de gerenciamento de projetos com IA que pode ser integrado opcionalmente ao ai-stack. Ele roda como uma **stack completamente independente** e se comunica com o ai-stack **apenas via LiteLLM Proxy**.

```mermaid
graph TB
    subgraph "Host Machine"
        LP["ğŸŒ LiteLLM Proxy<br/>localhost:4000<br/>Universal LLM Gateway"]
    end

    subgraph "ai-stack (Local Docker)"
        AS_DB["ğŸ—„ï¸ supabase-db<br/>:5432"]
        AS_PLANE_DB["ğŸ—„ï¸ postgres-plane<br/>:5433"]
        AS_NEO4J["ğŸ“Š Neo4j<br/>:7474/:7687"]
        AS_LIGHTRAG["ğŸ§  LightRAG<br/>:9621"]
        AS_N8N["âš™ï¸ n8n<br/>:5678"]
        AS_OWUI["ğŸ’¬ OpenWebUI<br/>:3001"]
    end

    subgraph "Archon Stack (Opcional - Local Docker)"
        AR_UI["ğŸ–¥ï¸ Archon UI<br/>:3737"]
        AR_SERVER["ğŸ”§ Archon Server<br/>:8181"]
        AR_MCP["ğŸ”— Archon MCP<br/>:8051"]
        AR_AGENTS["ğŸ¤– Archon Agents<br/>:8052"]
    end

    subgraph "Supabase Cloud"
        SC_DB["â˜ï¸ Archon Database<br/>Supabase Cloud"]
    end

    AS_LIGHTRAG -->|embeddings/chat| LP
    AS_N8N -->|LLM calls| LP
    AS_OWUI -->|LLM calls| LP

    AR_SERVER -->|LLM calls ONLY| LP
    AR_AGENTS -->|LLM calls ONLY| LP
    AR_SERVER -->|database| SC_DB
    AR_UI -->|REST API| AR_SERVER
    AR_MCP -->|tools| AR_SERVER

    style LP fill:#ffeb3b,stroke:#333,stroke-width:4px,color:#000
    style AR_SERVER fill:#4caf50,stroke:#333,stroke-width:3px,color:#fff
    style SC_DB fill:#2196f3,stroke:#333,stroke-width:3px,color:#fff
```

### 2.2 DecisÃµes Arquiteturais: Archon

| Aspecto | DecisÃ£o | Justificativa |
|---------|---------|---------------|
| **Database** | Supabase Cloud (separado) | âœ… Isolamento total do ai-stack<br/>âœ… Sem conflitos de porta/schema<br/>âœ… Backups gerenciados |
| **ComunicaÃ§Ã£o LLM** | Apenas via LiteLLM Proxy (4000) | âœ… Ponto Ãºnico de integraÃ§Ã£o<br/>âœ… Sem dependÃªncias diretas<br/>âœ… ReutilizaÃ§Ã£o de API keys |
| **Rede** | Stacks Docker independentes | âœ… Desacoplamento completo<br/>âœ… Pode rodar/parar independentemente<br/>âœ… Sem shared networks |
| **Portas** | Range 3737-8181 (sem conflitos) | âœ… NÃ£o sobrepÃµe portas do ai-stack<br/>âœ… FÃ¡cil identificaÃ§Ã£o |

### 2.3 ServiÃ§os Archon

| ServiÃ§o | Porta | FunÃ§Ã£o | Database |
|---------|-------|--------|----------|
| **Archon UI** | 3737 | Interface web React | Supabase Cloud (via Server) |
| **Archon Server** | 8181 | Backend FastAPI (CRUD, logic) | Supabase Cloud |
| **Archon MCP** | 8051 | MCP server for Claude Code tools | Supabase Cloud (via Server) |
| **Archon Agents** | 8052 | AI agent runtime (crawlers, analyzers) | Supabase Cloud (via Server) |

### 2.4 Quando Usar Archon?

**Use Archon se vocÃª precisa de:**
- âœ… Gerenciamento avanÃ§ado de projetos com IA
- âœ… Web crawling automÃ¡tico para anÃ¡lise de documentaÃ§Ã£o
- âœ… ExtraÃ§Ã£o automÃ¡tica de exemplos de cÃ³digo de repositÃ³rios
- âœ… IntegraÃ§Ã£o GitHub â†’ Tarefas com anÃ¡lise de IA
- âœ… MCP tools adicionais para Claude Code (`archon:rag_search_knowledge_base`, `archon:manage_project`, etc.)

**NÃƒO use Archon se:**
- âŒ VocÃª sÃ³ precisa de RAG bÃ¡sico (use LightRAG diretamente)
- âŒ Plane jÃ¡ atende suas necessidades de PM
- âŒ VocÃª quer minimizar complexidade (Archon adiciona 4 serviÃ§os)

### 2.5 ConfiguraÃ§Ã£o Archon (.env)

```bash
# /home/sedinha/ai-stack/Archon/.env

# âš ï¸ IMPORTANTE: Usar Supabase Cloud, NÃƒO supabase-db local!
SUPABASE_URL=https://seu-projeto.supabase.co
SUPABASE_SERVICE_KEY=eyJhbGci... # Service role key do Cloud

# âœ… CRÃTICO: Redirecionar LLM para LiteLLM Proxy do ai-stack
OPENAI_BASE_URL=http://host.docker.internal:4000/v1
OPENAI_API_KEY=sk-auto-headers-2025  # Usar LITELLM_MASTER_KEY do ai-stack

# Portas (evitar conflitos com ai-stack)
ARCHON_UI_PORT=3737
ARCHON_SERVER_PORT=8181
ARCHON_MCP_PORT=8051
ARCHON_AGENTS_PORT=8052
```

### 2.6 Comandos Archon

```bash
# Iniciar Archon (apÃ³s ai-stack e LiteLLM estarem rodando)
cd /home/sedinha/ai-stack/Archon
docker compose up -d

# Ver logs
docker compose logs -f archon-server
docker compose logs -f archon-agents

# Verificar saÃºde
curl http://localhost:8181/health
curl http://localhost:3737  # UI

# Parar Archon (nÃ£o afeta ai-stack)
docker compose down
```

### 2.7 MCP Tools Archon para Claude Code

Quando Archon estÃ¡ rodando, vocÃª pode usar estas ferramentas no Claude Code:

```json
// ~/.config/claude-code/mcp.json
{
  "mcpServers": {
    "archon": {
      "url": "http://localhost:8051"
    }
  }
}
```

**Ferramentas disponÃ­veis:**
- `archon:rag_search_knowledge_base` - Buscar na base de conhecimento do Archon
- `archon:find_projects` - Listar projetos
- `archon:manage_project` - Criar/atualizar/deletar projetos
- `archon:find_tasks` - Listar tarefas
- `archon:manage_task` - Criar/atualizar/deletar tarefas

### 2.8 Fluxo de Dados: ai-stack + Archon

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Claude Code (Local Development)        â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
    â”‚                                        â”‚
    â”‚ MCP: rag_search                        â”‚ MCP: archon:manage_project
    â”‚                                        â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastMCP Server    â”‚              â”‚  Archon MCP Server    â”‚
â”‚  (ai-stack)        â”‚              â”‚  (Archon)             â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                                        â”‚
    â”‚ HTTP: /query                           â”‚ HTTP: /api/projects
    â”‚                                        â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LightRAG Server   â”‚              â”‚  Archon Server        â”‚
â”‚  :9621             â”‚              â”‚  :8181                â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚       â”‚                                â”‚
    â”‚       â”‚                                â”‚
    â”‚       â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚       â”‚      â”‚
    â”‚       â”‚      â”‚ LLM requests (embeddings, chat)
    â”‚       â”‚      â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â” â”Œâ–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PG   â”‚ â”‚Neo4jâ”‚ â”‚  LiteLLM Proxy (Host:4000)       â”‚
â”‚:5432 â”‚ â”‚:7474â”‚ â”‚  âš¡ Single point of integration  â”‚
â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ OpenAI/Anthropic/GitHub APIs
                          â”‚
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚  External LLMs   â”‚
                  â”‚  (Claude, GPT-4) â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ponto-chave:** Archon e ai-stack se comunicam **apenas via LiteLLM Proxy** (porta 4000). NÃ£o hÃ¡ conexÃµes diretas entre bancos de dados ou serviÃ§os.

---

**ğŸ“ DocumentaÃ§Ã£o Relacionada:**
- [ARCHON_INTEGRATION.md](../docs/ARCHON_INTEGRATION.md) - Setup passo-a-passo do Archon
- [ARCHON_VALIDATION.md](../docs/ARCHON_VALIDATION.md) - Scripts de validaÃ§Ã£o
- [Resolvendo Problemas do Archon no Arch Linux](../docs/Resolvendo%20o%20Problema%20do%20Archon%20no%20Arch%20Linux.md) - Troubleshooting

**ğŸ“… Ãšltima AtualizaÃ§Ã£o:** 2025-01-28
